{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqgIc3BcRHWw"
      },
      "source": [
        "# Segment Anything PIV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRGs5wy6R-sb"
      },
      "source": [
        "## Installation & Current Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEX-Hg3qoeQn"
      },
      "source": [
        "Import packages already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Vuy-vYsBiBP"
      },
      "outputs": [],
      "source": [
        "## required packages\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tifffile # saving images to TIF\n",
        "import torch\n",
        "from PIL import Image, ImageEnhance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx5jhZGGfbUA"
      },
      "source": [
        "If using google colab, you can connect to your google drive folders and files with drive.mount:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P0_YeDtBB9M"
      },
      "outputs": [],
      "source": [
        "## mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "\n",
        "#put path to colab folder here ^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaGNjhuVfj1C"
      },
      "source": [
        "Install segment anything. Additionlly, you need to manually install the \"model checkpoints. From [Segment Anything Github Page](https://github.com/facebookresearch/segment-anything), scroll down until you get to the \"Model Checkpoints\" part. Then install any one of the models and **place them in the current directory specified above** (using %cd)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYIjKzpZAUKA"
      },
      "outputs": [],
      "source": [
        "# installation of segment anything\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MCxVqM_fiIq"
      },
      "source": [
        "Install packages required for segment anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSW6wH_RAgVV"
      },
      "outputs": [],
      "source": [
        "# installing requirements for segment anything\n",
        "!pip install opencv-python pycocotools matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GoCydUmf1Tq"
      },
      "source": [
        "Install packages that haven't been pre-installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L_rVcsqNBPf"
      },
      "outputs": [],
      "source": [
        "# install not pre-installed packages\n",
        "!pip install tifffile cv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Segmentation and Image Processing (No Classes/Functions)"
      ],
      "metadata": {
        "id": "hQwIZDCp9m0y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESicfaXb_Clh"
      },
      "source": [
        "###Image Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGDjSXHatrOf"
      },
      "source": [
        "#### Video to Frames\n",
        "If the images that you need to mask are in a video, use this to extract those images. Specify the path to the video, analyze all frames and then save each frame to an image file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jEdVNYstpqn"
      },
      "outputs": [],
      "source": [
        "\n",
        "video_path = '/content/drive/MyDrive/<path_to_your_video.mp4>'\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Initialize frame count\n",
        "frame_count = 0\n",
        "\n",
        "# Read the video frames and save them as images\n",
        "while True:\n",
        "    # Read the next frame\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Break the loop if no frame is captured\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save the frame as an image\n",
        "    image_path = f'video_frame/frame_{frame_count:04d}.jpg'\n",
        "    cv2.imwrite(image_path, frame)\n",
        "\n",
        "    # Increment frame count\n",
        "    frame_count += 1\n",
        "\n",
        "# Release the video file and close the image window\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOQUEzcZ2d7a"
      },
      "source": [
        "#### Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z08s_cM2jv8"
      },
      "source": [
        "Define path to the image folder and filename for testing, and define the path to put the processed images, created by the next code block. You can chnage one parameter (brightness, sharpness, or contrast) and compare those images with each other, or create one image with all of these changes combined. The images are then plotted and compared with the original."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test pre-processing before saving anything."
      ],
      "metadata": {
        "id": "shWgVhll4s_V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8KvVmT02hpj"
      },
      "outputs": [],
      "source": [
        "\n",
        "PATH_TO_IMG = ''\n",
        "\n",
        "PATH_TO_PROCESSED_IMG = ''\n",
        "\n",
        "filename = ''\n",
        "\n",
        "img_path = os.path.join(PATH_TO_IMG,filename)\n",
        "img = Image.open(img_path)\n",
        "\n",
        "#for changing parameters individually, creating images for each, and then comparing individual images\n",
        "\n",
        "contrast = ImageEnhance.Contrast(img)\n",
        "img_processed_contrast = contrast.enhance(4) #the numbers defined in .enhance() control the strength of the effect. 1 is the default\n",
        "\n",
        "brightness = ImageEnhance.Brightness(img)\n",
        "img_processed_brightness = brightness.enhance(0.5)\n",
        "\n",
        "sharpness = ImageEnhance.Sharpness(img)\n",
        "img_processed_sharpness = sharpness.enhance(4)\n",
        "\n",
        "#change any parameter and make single image with those changes\n",
        "\n",
        "def process_img(image,contrast,brightness,sharpness):\n",
        "  contraster = ImageEnhance.Contrast(image)\n",
        "  img_contrast = contraster.enhance(contrast)\n",
        "\n",
        "  brightnesser = ImageEnhance.Brightness(img_contrast)\n",
        "  img_brightness_and_contrast = brightnesser.enhance(brightness)\n",
        "\n",
        "  sharpnesser = ImageEnhance.Sharpness(img_brightness_and_contrast)\n",
        "  img_processed_sharpness_brightness_contrast = sharpnesser.enhance(sharpness)\n",
        "\n",
        "  return img_processed_sharpness_brightness_contrast\n",
        "\n",
        "#define strength of effects\n",
        "cont,br,sharp = 1,1,1\n",
        "\n",
        "img_processed = process_img(img,cont,br,sharp)\n",
        "\n",
        "#configure subplots to add differently processed images\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.subplot(4,1,1)\n",
        "plt.imshow(img,cmap='gray')\n",
        "plt.subplot(4,1,2)\n",
        "plt.imshow(img_processed,cmap='gray')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGnc_4yU2lE8"
      },
      "source": [
        "To pre-process all images in a folder afer testing. Path to the image folder and processed images folder specified above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "659xVaxg2nJ8"
      },
      "outputs": [],
      "source": [
        "#set the contrast, brightness and sharpness values\n",
        "cont, br, sharp = 1,1,1\n",
        "\n",
        "# create output folder if it does not exist\n",
        "if not os.path.exists(PATH_TO_PROCESSED_IMG):\n",
        "    os.makedirs(PATH_TO_PROCESSED_IMG)\n",
        "\n",
        "# loop through all the files in the folder\n",
        "for file in os.listdir(PATH_TO_IMG):\n",
        "  # open the image file\n",
        "  img_path = os.path.join(PATH_TO_IMG,file)\n",
        "  img = Image.open(img_path)\n",
        "  #use function to edit images\n",
        "  img_processed = process_img(img,cont,br,sharp)\n",
        "\n",
        "  out_path = os.path.join(PATH_TO_PROCESSED_IMG,file)\n",
        "  # save the edited image with the same filename\n",
        "  img_processed.save(out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dsvECN_gJZ5"
      },
      "source": [
        "#### Cropping of Images\n",
        "Used in case the region of interest is smaller than complete image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL5ZeHp1iGMJ"
      },
      "source": [
        "Specifiy image path, and path to save the cropped image.  The roi variable then crops the image using a rectangle with boundaries specified in an xyxy format (left side, top side, right side, and bottom side. To figure out where each point is, just plot the uncropped image instead and use plt.scatter to plot the point(s)).Then plot the cropped image."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test cropping of images before saving anything."
      ],
      "metadata": {
        "id": "TcM2GzUU4xgC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HXsVKXigMhZ"
      },
      "outputs": [],
      "source": [
        "# cropping of images, testing for one image without saving\n",
        "\n",
        "PATH_TO_IMG  = ''\n",
        "PATH_TO_CROP = ''\n",
        "filename = '' # image used for testing\n",
        "\n",
        "# set the region to be cropped in the format (left, upper, right, lower)\n",
        "roi  = (270, 400, 1150, 900)\n",
        "\n",
        "img_path = os.path.join(PATH_TO_IMG, filename)\n",
        "img = Image.open(img_path)\n",
        "\n",
        "# crop the image\n",
        "img_crop = img.crop(roi)\n",
        "\n",
        "plt.imshow(img_crop, cmap = 'gray')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xORXbgYivd3"
      },
      "source": [
        "To crop all images within a folder after testing. Path to the image folder and cropped images folder specified above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy9ISjIzjlS8"
      },
      "outputs": [],
      "source": [
        "# cropping of all images inside a folder\n",
        "\n",
        "# create output folder if it does not exist\n",
        "if not os.path.exists(PATH_TO_CROP):\n",
        "    os.makedirs(PATH_TO_CROP)\n",
        "\n",
        "# loop through all the files in the folder\n",
        "for filename in os.listdir(PATH_TO_IMG):\n",
        "    # open the image file\n",
        "    img_path = os.path.join(PATH_TO_IMG, filename)\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # crop the image\n",
        "    img_crop = img.crop(roi)\n",
        "\n",
        "    out_path = os.path.join(PATH_TO_CROP, filename)\n",
        "\n",
        "    # save the cropped image with the same filename\n",
        "    img_crop.save(out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual Segmentation (No Classes/Functions)"
      ],
      "metadata": {
        "id": "VMNXabJe94Y-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBAx8HkKSCJ5"
      },
      "source": [
        "#### Parameters\n",
        "\n",
        "Import segment anything, and specify the model and corresponding checkpoint being used (see above for instructions to download). Additionlly, specify the device being used for masking and specify the folders to the images and folder to save the masks to. Used for the mask generator and predictor code blocks that arent functions or classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UQ9I24fSSO1"
      },
      "outputs": [],
      "source": [
        "# segment anyting\n",
        "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry, SamPredictor\n",
        "model_type = 'default' # 'default', \"vit_l\", \"vit_b\"\n",
        "\n",
        "match model_type:\n",
        "\n",
        "  # put the downloaded checkpoints into /content/drive/MyDrive/Colab Notebooks; whatever the path you set in 2nd code block\n",
        "  case 'default':\n",
        "    checkpoint = 'sam_vit_h_4b8939.pth'\n",
        "\n",
        "  case 'vit_l':\n",
        "    checkpoint = 'sam_vit_l_0b3195.pth'\n",
        "\n",
        "  case 'vit_b':\n",
        "    checkpoint = 'sam_vit_b_01ec64.pth'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # if available use GPU for speed-up\n",
        "\n",
        "# image folder and folder for masking\n",
        "PATH_TO_IMG  = ''\n",
        "PATH_TO_MASK = ''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUWoujtb7dQa"
      },
      "source": [
        "#### Mask Generator\n",
        "* creation of masks for the whole image\n",
        "\n",
        "Automatically creates mask for images without specification of any particular places/objects to mask. Recommended for simple images with one mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywRUnmT7YLiu"
      },
      "outputs": [],
      "source": [
        "#set up sam masking\n",
        "sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
        "sam.to(device)\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "\n",
        "# create output folder if it does not exist\n",
        "if not os.path.exists(PATH_TO_MASK):\n",
        "    os.makedirs(PATH_TO_MASK)\n",
        "\n",
        "for filename in os.listdir(PATH_TO_IMG):\n",
        "  # read image\n",
        "  img_path = os.path.join(PATH_TO_IMG, filename)\n",
        "  img = np.array(Image.open(img_path).convert('RGB'))# use of PIL to ensure compatible with PyTorch\n",
        "\n",
        "  # masking\n",
        "\n",
        "  mask = mask_generator.generate(img)\n",
        "\n",
        "  # output image\n",
        "  out = mask[0]['segmentation']\n",
        "  out = np.logical_not(out)\n",
        " # out = cv2.bitwise_not(out.astype(np.uint8)).astype(bool) # use this in case masked and unmasked areas are flipped\n",
        "  outname = 'mask_' + filename.replace('.jpg', '.tif')\n",
        "\n",
        "  # save binary mask to output folder with same filename\n",
        "  output_path = os.path.join(PATH_TO_MASK, outname)\n",
        "  tifffile.imwrite(output_path, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0NYReIY7tZR"
      },
      "source": [
        "#### Predictor\n",
        "* creation of multiple masks from images and bonding boxes\n",
        "* recommended for images that need manual masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvjbl2I8k69h"
      },
      "source": [
        "Preview a specified image for masking using the Predictor. Specify image path, plot the image as well as a specific point used for the Predictor masking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK6d9L7Uk0Oq"
      },
      "outputs": [],
      "source": [
        "put_img_file_here = 'img_00250.jpg'\n",
        "img_file = os.path.join(PATH_TO_IMG, put_img_file_here)\n",
        "img = Image.open(img_file)\n",
        "\n",
        "x,y = 2000,1750   #specify location of point to observe\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "plt.scatter(x,y)\n",
        "print(img_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr0u3uB5l0Ns"
      },
      "source": [
        "Mask using the Predictor. Use input_point to mask specific objects in the image, input_label to give these points a marker, and input_box to specify a box to mask.\n",
        "\n",
        "For the point, you can specify numerous points on the same object via np.array([[x1,y1],[x2,y2],...,[xn,yn]]). If you decide to do this, you must label each point, for example, np.array([0,0,0,1, etc.]).\n",
        "\n",
        "You can use a combination of box and point for further specification on what to mask.\n",
        "\n",
        "You can also mask additional objects in the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM8mSrwvpLtw"
      },
      "outputs": [],
      "source": [
        "#640, 150 and 225, 150\n",
        "input_point = np.array([[400,300]]) #specify point to mask an object\n",
        "input_point_2 = np.array([[225,150]])\n",
        "input_label = np.array([1]) #0 or 1 for negative or positive input\n",
        "\n",
        "input_box = np.array([0,290,925,460])   #box to mask, in xyxy format (left side, top side, right side, and bottom side of box)\n",
        "\n",
        "#setup mask\n",
        "\n",
        "PATH_TO_IMG = '/content/drive/MyDrive/2023UGSRP_FSI/Image_Seg./ct/test1/one_img'\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
        "sam.to(device)\n",
        "predictor = SamPredictor(sam)\n",
        "\n",
        "# create output folder if it does not exist\n",
        "if not os.path.exists(PATH_TO_MASK):\n",
        "    os.makedirs(PATH_TO_MASK)\n",
        "\n",
        "for filename in os.listdir(PATH_TO_IMG):\n",
        "  # read image\n",
        "  img_path = os.path.join(PATH_TO_IMG, filename)\n",
        "  img = np.array(Image.open(img_path).convert('RGB')) # use of PIL to ensure compatible with PyTorch\n",
        "\n",
        "  # masking\n",
        "  predictor.set_image(img)\n",
        "\n",
        "  mask ,_, _ = predictor.predict(\n",
        "      point_coords=input_point,\n",
        "      point_labels=input_label,\n",
        "      #box = input_box,           #optional box\n",
        "      multimask_output=False,\n",
        "  )\n",
        "  #To mask a second object\n",
        "  # mask_2 ,_, _ = predictor.predict(\n",
        "  #    point_coords=input_point_2,\n",
        "  #    point_labels=input_label_2,\n",
        "  #    #box = input_box_2,\n",
        "  #    multimask_output=False,\n",
        "  #)\n",
        "\n",
        "  out = mask # |mask_2\n",
        "  out = np.logical_not(out)     #flips unmasked and masked portions of images\n",
        "\n",
        "  outname = 'mask_' + filename.replace('.jpg', '.tif')\n",
        "\n",
        "  # save binary mask to output folder with same filename\n",
        "  output_path = os.path.join(PATH_TO_MASK, outname)\n",
        "  tifffile.imwrite(output_path, out)\n",
        "  print(img_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic Segmentation and Image Processing (Uses Classes/Functions)\n",
        "\n",
        "Contains a Dataset class to specify and obtain path to images, an Image Processing class to process images and the Masking class to mask images."
      ],
      "metadata": {
        "id": "gNQM49WK7ps0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Class\n",
        "\n",
        "\n",
        "Set image path and optional mask path and path to process images. Use the class functions to retrieve the image path, mask path and processed image paths."
      ],
      "metadata": {
        "id": "Fz23Fxmj7x7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset():\n",
        "\n",
        "  #Define all paths as strings. img_path used for the original set of images,\n",
        "  #processed_img_path will hold the edited images, and mask_path is where to put the masked images\n",
        "  #Can automatically make the mask and processed img folders\n",
        "\n",
        "  def __init__(self, img_path,mask_path='',processed_img_path = '',):\n",
        "    self.image_path = img_path\n",
        "\n",
        "    self.processed_img_path = processed_img_path\n",
        "\n",
        "    self.mask_path = mask_path\n",
        "\n",
        "  def get_img_path(self):\n",
        "\n",
        "    return self.image_path\n",
        "\n",
        "  def get_processed_img_path(self):\n",
        "    #make folder if it doesnt exist\n",
        "    if not os.path.exists(self.processed_img_path):\n",
        "        os.makedirs(self.processed_img_path)\n",
        "\n",
        "    return self.processed_img_path\n",
        "\n",
        "  def get_mask_path(self):\n",
        "    #make folder if it doesnt exist\n",
        "    if not os.path.exists(self.mask_path):\n",
        "      os.makedirs(self.mask_path)\n",
        "\n",
        "    return self.mask_path"
      ],
      "metadata": {
        "id": "XUGMzTpp7tDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Processing Class\n",
        "\n",
        "Edit images by cropping and/or changing the contrast, brightness and/or sharpness. For each function, define the input path for the images to edit, the editing parameters, and output path to store the edited images. The paths should be obtained via the dataset class.\n",
        "\n"
      ],
      "metadata": {
        "id": "3STZigef8LwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input and output paths defined with dataset class\n",
        "class process_img():\n",
        "\n",
        "#define input folder with original images, output folder to put edited images, and strength of effect (value > 0)\n",
        "  def contrast(self,input_path,contrast_value,output_path):\n",
        "    for file in os.listdir(input_path):\n",
        "      img_path = os.path.join(input_path,file)\n",
        "      img = Image.open(img_path)\n",
        "      contraster = ImageEnhance.Contrast(img)\n",
        "      img_contrast = contraster.enhance(contrast_value)\n",
        "\n",
        "      out_path = os.path.join(output_path,file)\n",
        "      img_contrast.save(out_path)\n",
        "\n",
        "#define input folder with original images, output folder to put edited images, and strength of effect (value > 0)\n",
        "  def brightness(self,input_path,brightness_value,output_path):\n",
        "    for file in os.listdir(input_path):\n",
        "      img_path = os.path.join(input_path,file)\n",
        "      img = Image.open(img_path)\n",
        "      brightnesser = ImageEnhance.Brightness(img)\n",
        "      img_brightness = brightnesser.enhance(brightness_value)\n",
        "\n",
        "      out_path = os.path.join(output_path,file)\n",
        "      img_brightness.save(out_path)\n",
        "\n",
        "\n",
        "#define input folder with original images, output folder to put edited images, and strength of effect (value > 0)\n",
        "  def sharpness(self,input_path,sharpness_value,output_path):\n",
        "      for file in os.listdir(input_path):\n",
        "        img_path = os.path.join(input_path,file)\n",
        "        img = Image.open(img_path)\n",
        "        sharpnesser = ImageEnhance.Sharpness(img)\n",
        "        img_sharpness = sharpnesser.enhance(sharpness_value)\n",
        "\n",
        "        out_path = os.path.join(output_path,file)\n",
        "        img_sharpness.save(out_path)\n",
        "\n",
        "#define input folder with original images, output folder to put edited images, and strength of effect (value > 0)\n",
        "  def crop(self,input_path,roi,output_path):\n",
        "      for file in os.listdir(input_path):\n",
        "        img_path = os.path.join(input_path,file)\n",
        "        img = Image.open(img_path)\n",
        "        img_crop = img.crop(roi)\n",
        "\n",
        "        out_path = os.path.join(output_path,file)\n",
        "        img_crop.save(out_path)\n"
      ],
      "metadata": {
        "id": "SOaJnMJp8PbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example using Dataset class and Image Processing class."
      ],
      "metadata": {
        "id": "zntKD8Cc8lD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "d = dataset('Flag_and_Foil/one_img',processed_img_path='Flag_and_Foil/one_img_test')\n",
        "roi  = (270, 400, 1150, 900)\n",
        "\n",
        "input = d.get_img_path()\n",
        "\n",
        "output = d.get_processed_img_path()\n",
        "\n",
        "p = process_img()\n",
        "p.crop(input,roi,output)\n",
        "sleep(8) #gives google drive enough time to update files\n",
        "p.contrast(output,4,output)\n",
        "sleep(8)\n",
        "p.brightness(output,2,output)"
      ],
      "metadata": {
        "id": "icOzUGkq8qar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking Class"
      ],
      "metadata": {
        "id": "tHu07Pgr9R1l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnFuYhv2jTqI"
      },
      "source": [
        "#### How to Use the Predictor Functions within the Masking Class:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCip1pMyk3Ei"
      },
      "source": [
        "\n",
        "For using **only** points to mask, any number of points can be used for a singular object and must be of the form:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOdY9Y5blzx4",
        "outputId": "91fc5691-ccbf-4005-83db-71b1ea701132"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[200, 200], [200, 200]]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_point = [[[200,200],[200,200]]]\n",
        "input_point[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPSdKszmmDMA"
      },
      "source": [
        "Here, we use 2 points for one object. Calling the first index of the list will give the above output, **such that len(input_point) is 1**. You can also specify multiple points for various objects:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv8aNTxLl566",
        "outputId": "8c220b37-cdf4-4b51-c559-b8f5af5492af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[200, 200], [200, 200]], [[300, 300], [300, 300]], 2)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "input_point = [[[200,200],[200,200]],[[300,300],[300,300]]]\n",
        "input_point[0],input_point[1],len(input_point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owhB2surmoNv"
      },
      "source": [
        "\n",
        "Here, we use 2 points for each object. The first index of the input_point list labels points for the first object, and the second index for the second object, etc. **Calling len(input_point) should give the number of objects (2 in this case)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkwQ9dy9lxTx"
      },
      "source": [
        "For each point, there must be a specified label assigned. 1 is for positive inputs, and a -1 is for negative inputs. See the github page for more info. For the points specified above, the input label should look like such:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcWDYukQl_PP"
      },
      "outputs": [],
      "source": [
        "input_label = [[1,1],[1,1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjQQPyqWmQto"
      },
      "source": [
        "Where we assign a value of 1 for each point. **Again, len(input_label) should be the number of objects.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fszeBTXfmdOn"
      },
      "source": [
        "The same idea applies for using **only** boxes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-mua1Ammf1-",
        "outputId": "c2f76be0-8def-4c7c-ff5f-83470ebb851d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 2, 3, 4], [5, 6, 7, 8], 2)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "input_box = [[1,2,3,4],[5,6,7,8]]\n",
        "input_box[0], input_box[1],len(input_box)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLXexyf1msyv"
      },
      "source": [
        "Again, the first index of the input_box list is for the first object, the second index for the second object, and so on. **Using len(input_box) should once again give the number of objects (2 in this case).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbaTYcgsmmUo"
      },
      "source": [
        " However, if, for example, you have two objects and you want to use only points for the first object and only boxes for the second, you must place a [0] in the corresponding lists to indicate this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-uIkgpynKK3",
        "outputId": "1350aba7-f8ad-4cf8-d4b0-528a8565fde8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_point = [[[200,200]],[0]]\n",
        "input_label = [[1],[0]]\n",
        "input_box = [[0],[1,2,3,4]]\n",
        "len(input_point) == len(input_box) == len(input_label) == 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv1ke5XCnyAY"
      },
      "source": [
        "As shown, a [0] is placed in the second index in input_point and input_label as we dont want to use a point for the second object. Similarly, a [0] is placed in the first index for input_box as we dont want to use boxes to mask the first object.\n",
        "\n",
        "\n",
        "In general, the [0] is placed in the n_th entry of the list where n is the number of the object where we don't want either a point or box masking for that object.\n",
        "\n",
        "\n",
        "It is done this way to keep track of the different combinations of points/boxes that are being used for each object being masked, and such that len() of the point, label and box lists are all equal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiK7eJbxkEPH"
      },
      "source": [
        "Code below, with an example of masking 2 objects, using 1 point each. Path to the image and mask folders must be specified. Additionally, model_type has to be specified and there is an option to invert the mask (change black to white and vice versa). A value of invert=1 inverts the mask, and invert=0 keeps it as is. The default is invert=0."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preview Point on Image\n",
        "\n",
        "Preview a specified image for masking using the Predictor. Specify image path, plot the image as well as a specific point used for the Predictor masking."
      ],
      "metadata": {
        "id": "GLfx4YiCDgcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_IMG = ''\n",
        "put_img_file_here = ''\n",
        "img_file = os.path.join(PATH_TO_IMG, put_img_file_here)\n",
        "img = Image.open(img_file)\n",
        "\n",
        "x,y = 2000,1750   #specify location of point to observe\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "plt.scatter(x,y)\n",
        "print(img_file)"
      ],
      "metadata": {
        "id": "IgkI36y3Dg8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mask Class\n",
        "\n",
        "Mask images. Set model type. Then choose to mask using points, boxes or acombination. An optional parameter to invert the colors of the mask is available (just set invert=True).\n",
        "\n",
        "You can either use the mask_generator (the first function) or the mask_predictor (the second, third and fourth functions)."
      ],
      "metadata": {
        "id": "3pKbE5KilS8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class mask():\n",
        "\n",
        "  def __init__(self,model_type):\n",
        "\n",
        "    from segment_anything import SamAutomaticMaskGenerator, sam_model_registry, SamPredictor\n",
        "    self.model_type = model_type # 'default', \"vit_l\", \"vit_b\"\n",
        "\n",
        "    match self.model_type:\n",
        "\n",
        "  # define path of downloaded checkpoint(s) from github page\n",
        "      case 'default':\n",
        "          checkpoint = 'sam_vit_h_4b8939.pth'\n",
        "\n",
        "      case 'vit_l':\n",
        "          checkpoint = 'sam_vit_l_0b3195.pth'\n",
        "\n",
        "      case 'vit_b':\n",
        "          checkpoint = 'sam_vit_b_01ec64.pth'\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # if available use GPU for speed-up\n",
        "\n",
        "    sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
        "    sam.to(device)\n",
        "    predictor = SamPredictor(sam)\n",
        "    generator = SamAutomaticMaskGenerator(sam)\n",
        "    self.generator = generator\n",
        "    self.predictor = predictor\n",
        "\n",
        "#for automatically creating masks without specifying points/boxes\n",
        "def mask_generator(self,PATH_TO_IMG,PATH_TO_MASK):\n",
        "\n",
        "  # create output folder if it does not exist\n",
        "  if not os.path.exists(PATH_TO_MASK):\n",
        "    os.makedirs(PATH_TO_MASK)\n",
        "\n",
        "  for filename in os.listdir(PATH_TO_IMG):\n",
        "   # read image\n",
        "    img_path = os.path.join(PATH_TO_IMG, filename)\n",
        "    img = np.array(Image.open(img_path).convert('RGB'))# use of PIL to ensure compatible with PyTorch\n",
        "\n",
        "   # masking\n",
        "    mask = self.generator.generate(img)\n",
        "\n",
        "    #output image\n",
        "    out = mask[0]['segmentation']\n",
        "    out = np.logical_not(out)\n",
        "\n",
        "  # out = cv2.bitwise_not(out.astype(np.uint8)).astype(bool) # use this in case masked and unmasked areas are flipped\n",
        "    outname = 'mask_' + filename.replace('.jpg', '.tif')\n",
        "\n",
        "    # save binary mask to output folder with same filename\n",
        "    output_path = os.path.join(PATH_TO_MASK, outname)\n",
        "    tifffile.imwrite(output_path, out)\n",
        "\n",
        "#for masking using only points, paths defined as strings; points and labels defined as lists\n",
        "  def mask_point(self,path_to_img,path_to_mask,input_point,input_label,invert=False):\n",
        "    for filename in os.listdir(path_to_img):\n",
        "    # read image\n",
        "        img_path = os.path.join(path_to_img, filename)\n",
        "        img = np.array(Image.open(img_path).convert('RGB')) # use of PIL to ensure compatible with PyTorch\n",
        "\n",
        "    # masking\n",
        "        self.predictor.set_image(img)\n",
        "        out = 0\n",
        "\n",
        "        #for loops are for masking multiple different objects\n",
        "        for i,j in zip(input_point,input_label):\n",
        "\n",
        "         #masking object with no box\n",
        "          mask ,_, _ = self.predictor.predict(\n",
        "                    point_coords=np.array(i),\n",
        "                    point_labels=np.array(j),\n",
        "                    multimask_output=False\n",
        "    )\n",
        "\n",
        "          #convert masks to type bool and combine all masks\n",
        "          mask = np.array(mask,dtype=bool)\n",
        "          out |= mask\n",
        "\n",
        "        #convert out to type bool\n",
        "        out = np.array(out,dtype=bool)\n",
        "\n",
        "        #invert mask colors\n",
        "        if invert == True:\n",
        "          out = np.logical_not(out)\n",
        "\n",
        "        #save binary mask to output folder with same filename\n",
        "        outname = 'mask_' + filename.replace('.jpg', '.tif')\n",
        "        output_path = os.path.join(path_to_mask, outname)\n",
        "        tifffile.imwrite(output_path, out)\n",
        "\n",
        "#for masking using only boxes; paths defined as strings; box defined with list in xyxy format\n",
        "  def mask_box(self,path_to_img,path_to_mask,input_box,invert=False):\n",
        "    for filename in os.listdir(path_to_img):\n",
        "    # read image\n",
        "        img_path = os.path.join(path_to_img, filename)\n",
        "        img = np.array(Image.open(img_path).convert('RGB')) # use of PIL to ensure compatible with PyTorch\n",
        "\n",
        "    # masking\n",
        "        self.predictor.set_image(img)\n",
        "        out = 0\n",
        "\n",
        "        #for loops are for masking multiple different objects\n",
        "\n",
        "        for i in zip(input_box):\n",
        "\n",
        "         #masking object with no box\n",
        "          mask ,_, _ = self.predictor.predict(\n",
        "                    box = np.array(i),\n",
        "                    multimask_output=False\n",
        "    )\n",
        "          #convert masks to type bool and combine all masks\n",
        "          mask = np.array(mask,dtype=bool)\n",
        "          out |= mask\n",
        "\n",
        "        #convert out to type bool\n",
        "        out = np.array(out,dtype=bool)\n",
        "\n",
        "        #invert mask colors\n",
        "        if invert == True:\n",
        "          out = np.logical_not(out)\n",
        "\n",
        "        #save binary mask to output folder with same filename\n",
        "        outname = 'mask_' + filename.replace('.jpg', '.tif')\n",
        "        output_path = os.path.join(path_to_mask, outname)\n",
        "        tifffile.imwrite(output_path, out)\n",
        "\n",
        "#for masking using combination of points and boxes; paths defined as strings; points, labels and boxes defined as stated above\n",
        "  def mask_box_point(self,path_to_img,path_to_mask,input_point,input_label,input_box,invert=False):\n",
        "\n",
        "    for filename in os.listdir(path_to_img):\n",
        "    # read image\n",
        "        img_path = os.path.join(path_to_img, filename)\n",
        "        img = np.array(Image.open(img_path).convert('RGB')) # use of PIL to ensure compatible with PyTorch\n",
        "\n",
        "    # masking\n",
        "        self.predictor.set_image(img)\n",
        "        out = 0\n",
        "\n",
        "    #for loops are for masking multiple different object\n",
        "        for l,m,n in zip(input_point,input_label,input_box):\n",
        "\n",
        "            if l == [0]: #masking object with no point\n",
        "                mask ,_, _ = self.predictor.predict(\n",
        "                    box = np.array(n),\n",
        "                    multimask_output=False,\n",
        "    )\n",
        "            elif n == [0]: #masking object with no box\n",
        "                mask ,_, _ = self.predictor.predict(\n",
        "                    point_coords=np.array(l),\n",
        "                    point_labels=np.array(m),\n",
        "                    multimask_output=False,\n",
        "        )\n",
        "            elif (l !=[0]) & (n !=[0]): #masking object with both point and box\n",
        "                mask ,_, _ = self.predictor.predict(\n",
        "                    point_coords=np.array(l),\n",
        "                    point_labels=np.array(m),\n",
        "                    box = np.array(n),\n",
        "                    multimask_output=False\n",
        "    )\n",
        "\n",
        "            #convert masks to type bool and combine all masks\n",
        "            mask = np.array(mask,dtype=bool)\n",
        "            out |= mask\n",
        "\n",
        "        #convert out to type bool\n",
        "        out = np.array(out,dtype=bool)\n",
        "        #invert mask colors\n",
        "        if invert == True:\n",
        "          out = np.logical_not(out)\n",
        "\n",
        "        #save binary mask to output folder with same filename\n",
        "        outname = 'mask_' + filename.replace('.jpg', '.tif')\n",
        "        output_path = os.path.join(path_to_mask, outname)\n",
        "        tifffile.imwrite(output_path, out)\n",
        "\n"
      ],
      "metadata": {
        "id": "jqrEqX4rtr3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example using Dataset class, Image Processing class, and Mask class:"
      ],
      "metadata": {
        "id": "66EN4typD7LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset('/content/drive/MyDrive/4 3.8f',processed_img_path='Fish/crop',mask_path='Fish/mask_fish_box_point')\n",
        "img = data.get_img_path()\n",
        "mask_path = data.get_mask_path()\n",
        "processed_img_path = data.get_processed_img_path()\n",
        "box = [[405,340,1175,550]]\n",
        "input_label = [[1,1]]\n",
        "point_tail = [[[1020,415],[1020,445]]]"
      ],
      "metadata": {
        "id": "GS_YE0QtEAIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = process_img()\n",
        "p.crop(img,[0,0,1600,965],processed_img_path)"
      ],
      "metadata": {
        "id": "S8y2tGfhEBCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_fish = mask('default')"
      ],
      "metadata": {
        "id": "CneYifFfEC-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_fish.mask_box_point(processed_img_path,mask_path,point_tail,input_label,box)"
      ],
      "metadata": {
        "id": "ks-uAdbbEE3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}